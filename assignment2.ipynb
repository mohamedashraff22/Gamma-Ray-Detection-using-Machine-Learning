{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split #for splitting data\n",
    "from imblearn.over_sampling import RandomOverSampler # for oversamples(gamma and hadrons)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV , KFold# for crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConc1</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fLength    fWidth   fSize   fConc  fConc1     fAsym  fM3Long  fM3Trans  \\\n",
       "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110   -8.2027   \n",
       "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238   -9.9574   \n",
       "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580  -45.2160   \n",
       "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633   -7.1513   \n",
       "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525   21.8393   \n",
       "\n",
       "    fAlpha     fDist class  \n",
       "0  40.0920   81.8828     g  \n",
       "1   6.3609  205.2610     g  \n",
       "2  76.9600  256.7880     g  \n",
       "3  10.4490  116.7370     g  \n",
       "4   4.6480  356.4620     g  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"fLength\" , \"fWidth\" , \"fSize\" , \"fConc\" , \"fConc1\" , \"fAsym\" , \"fM3Long\" , \"fM3Trans\" , \"fAlpha\" , \"fDist\" , \"class\"]\n",
    "# turn data csv to data frame object\n",
    "df = pd.read_csv(\"magic04.data\" , names=cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConc1</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fLength    fWidth   fSize   fConc  fConc1     fAsym  fM3Long  fM3Trans  \\\n",
       "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110   -8.2027   \n",
       "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238   -9.9574   \n",
       "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580  -45.2160   \n",
       "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633   -7.1513   \n",
       "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525   21.8393   \n",
       "\n",
       "    fAlpha     fDist  class  \n",
       "0  40.0920   81.8828      1  \n",
       "1   6.3609  205.2610      1  \n",
       "2  76.9600  256.7880      1  \n",
       "3  10.4490  116.7370      1  \n",
       "4   4.6480  356.4620      1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# g ==> gamma , h ==> hadrons , and convert g ==> 1 & h ==> 0\n",
    "df[\"class\"].unique()\n",
    "df[\"class\"] = (df[\"class\"] == 'g').astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of whole data 19020\n",
      "Train data number  13313\n",
      "vVlidation data number  2854\n",
      "Test data number  2853\n"
     ]
    }
   ],
   "source": [
    "# use numpy to split data\n",
    "# first place i will split dataframe at 70% then at 85% , every thing between 70% and 85% will go to ==> validate\n",
    "train_validate, test = train_test_split(df, test_size=0.15, random_state=42)\n",
    "train , valid = train_test_split(train_validate, test_size=0.1765, random_state=42)\n",
    "\n",
    "print(\"Length of whole data\" , len(df))\n",
    "print (\"Train data number \" , len(train) )\n",
    "print (\"vVlidation data number \" , len(valid) )\n",
    "print (\"Test data number \" , len(test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8646\n",
      "4667\n"
     ]
    }
   ],
   "source": [
    "print(len(train[train[\"class\"]==1])) # print number of gammas\n",
    "print(len(train[train[\"class\"]==0])) # hadrons\n",
    "# data of gammas is much more ==> so i will use oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversammpling function\n",
    "# oversample is false for default\n",
    "def scale_dataset(dataframe, oversample=False):\n",
    "  # the labels will gonna be the last thing in the dataframe.\n",
    "  X = dataframe[dataframe.columns[:-1]].values # Features\n",
    "  y = dataframe[dataframe.columns[-1]].values  # Output\n",
    "\n",
    "  if oversample:\n",
    "   ros = RandomOverSampler()\n",
    "   X, y = ros.fit_resample(X, y)\n",
    "\n",
    "  # horizentaly stack the data (not on top of each other) ==> the whole data as huge numpy array.\n",
    "  # I'll use reshape as x is 2D but y is 1d(vector) , -1 == len(y).\n",
    "  data = np.hstack((X , np.reshape(y , (-1 , 1))))\n",
    "  \n",
    "  return data ,X ,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, X_train, y_train = scale_dataset(train, oversample=True)\n",
    "valid, X_valid, y_valid = scale_dataset(valid, oversample=False)\n",
    "test, X_test, y_test = scale_dataset(test, oversample=False)\n",
    "# In validate and test data i dont care about oversampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " check balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17292\n",
      "8646\n",
      "8646\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "# train data are equal now\n",
    "print(sum(y_train == 1))\n",
    "print(sum(y_train == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "#scale train data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "#scale test data\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8030143708377147\n",
      "Precision: 0.8488624052004333\n",
      "Recall: 0.847027027027027\n",
      "F1-score: 0.8479437229437229\n",
      "Confusion Matrix:\n",
      "[[ 724  279]\n",
      " [ 283 1567]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train the decision tree classifier\n",
    "decision_tree_classifier = DecisionTreeClassifier() # take object\n",
    "decision_tree_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_decision_tree = decision_tree_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "accuracy_decision_tree = accuracy_score(y_test, y_pred_decision_tree)\n",
    "precision_decision_tree = precision_score(y_test, y_pred_decision_tree)\n",
    "recall_decision_tree = recall_score(y_test, y_pred_decision_tree)\n",
    "f1_score_decision_tree = f1_score(y_test, y_pred_decision_tree)\n",
    "confusion_matrix_decision_tree = confusion_matrix(y_test, y_pred_decision_tree)\n",
    "print(\"Accuracy:\" , accuracy_decision_tree)\n",
    "print(\"Precision:\", precision_decision_tree)\n",
    "print(\"Recall:\" , recall_decision_tree)\n",
    "print(\"F1-score:\" , f1_score_decision_tree)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7266035751840169\n",
      "Precision: 0.7358906525573192\n",
      "Recall:  0.9021621621621622\n",
      "F1-score: 0.8105876639145216\n",
      "Confusion Matrix:\n",
      "[[ 404  599]\n",
      " [ 181 1669]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "naive_bayes_classifier = GaussianNB()\n",
    "naive_bayes_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions on testing data\n",
    "y_pred_naive_bayes = naive_bayes_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "accuracy_naive_bayes = accuracy_score(y_test, y_pred_naive_bayes)\n",
    "precision_naive_bayes = precision_score(y_test, y_pred_naive_bayes)\n",
    "recall_naive_bayes = recall_score(y_test, y_pred_naive_bayes)\n",
    "f1_score_naive_bayes = f1_score(y_test, y_pred_naive_bayes)\n",
    "confusion_matrix_naive_bayes = confusion_matrix(y_test, y_pred_naive_bayes)\n",
    "print(\"Accuracy:\" , accuracy_naive_bayes)\n",
    "print(\"Precision:\" , precision_naive_bayes)\n",
    "print(\"Recall: \", recall_naive_bayes)\n",
    "print(\"F1-score:\" , f1_score_naive_bayes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_naive_bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_estimators: 200\n",
      "Accuracy: 0.8086225026288117\n",
      "Precision: 0.8862559241706162\n",
      "Recall: 0.8086486486486486\n",
      "F1-score: 0.8456755228942906\n",
      "Confusion Matrix:\n",
      "[[ 811  192]\n",
      " [ 354 1496]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#define estimators\n",
    "param_n_estimators = [50, 100, 200]  # Number of weak learners\n",
    "\n",
    "#arrays to store metrics\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "#define k-fold cross-validation\n",
    "k_folds = 5\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "#Iterate over each estimators\n",
    "for n_estimators in param_n_estimators:\n",
    "    adaboost_classifier = AdaBoostClassifier(n_estimators=n_estimators, algorithm='SAMME')\n",
    "    fold_accuracy = []\n",
    "    fold_precision = []\n",
    "    fold_recall = []\n",
    "    fold_f1 = []\n",
    "    \n",
    "    #Perform k-fold cross-validation on each estimator\n",
    "    for train_index, test_index in kf.split(X_train_scaled):\n",
    "        X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n",
    "        \n",
    "        adaboost_classifier.fit(X_train_fold, y_train_fold)\n",
    "        y_pred_fold = adaboost_classifier.predict(X_val_fold)\n",
    "        \n",
    "        fold_accuracy.append(accuracy_score(y_val_fold, y_pred_fold))\n",
    "        fold_precision.append(precision_score(y_val_fold, y_pred_fold))\n",
    "        fold_recall.append(recall_score(y_val_fold, y_pred_fold))\n",
    "        fold_f1.append(f1_score(y_val_fold, y_pred_fold))\n",
    "    \n",
    "    #average scores across folds\n",
    "    accuracy_scores.append(np.mean(fold_accuracy))\n",
    "    precision_scores.append(np.mean(fold_precision))\n",
    "    recall_scores.append(np.mean(fold_recall))\n",
    "    f1_scores.append(np.mean(fold_f1))\n",
    "\n",
    "#find the best estimator depends on the average accuracy form each fold\n",
    "best_index = np.argmax(accuracy_scores)\n",
    "best_n_estimators = param_n_estimators[best_index]\n",
    "\n",
    "#train the best model\n",
    "best_adaboost_classifier = AdaBoostClassifier(n_estimators=best_n_estimators)\n",
    "best_adaboost_classifier.fit(X_train_scaled, y_train)\n",
    "#Prediction\n",
    "y_pred_adaboost = best_adaboost_classifier.predict(X_test_scaled)\n",
    "\n",
    "#evaluation\n",
    "accuracy_adaboost = accuracy_score(y_test, y_pred_adaboost)\n",
    "precision_adaboost = precision_score(y_test, y_pred_adaboost)\n",
    "recall_adaboost = recall_score(y_test, y_pred_adaboost)\n",
    "f1_score_adaboost = f1_score(y_test, y_pred_adaboost)\n",
    "confusion_matrix_adaboost = confusion_matrix(y_test, y_pred_adaboost)\n",
    "print(\"Best estimators:\", best_n_estimators)\n",
    "print(\"Accuracy:\", accuracy_adaboost)\n",
    "print(\"Precision:\", precision_adaboost)\n",
    "print(\"Recall:\", recall_adaboost)\n",
    "print(\"F1-score:\", f1_score_adaboost)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_adaboost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_estimators: 300\n",
      "Random Forest Classifier Metrics:\n",
      "Accuracy: 0.8741675429372591\n",
      "Precision: 0.886870783601453\n",
      "Recall: 0.9237837837837838\n",
      "F1-score: 0.9049510193275087\n",
      "Confusion Matrix:\n",
      "[[ 785  218]\n",
      " [ 141 1709]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#define classifier (take object)\n",
    "random_forest_classifier = RandomForestClassifier()\n",
    "\n",
    "# Define parameter tuning n_estimators\n",
    "param_grid_random_forest = {'n_estimators': [75, 150, 300]}\n",
    "\n",
    "#arrays to store metrics\n",
    "accuracy_random_forest = []\n",
    "precision_random_forest = []\n",
    "recall_random_forest = []\n",
    "f1_score_random_forest = []\n",
    "\n",
    "#define k-fold cross-validation\n",
    "k_folds = 5\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "#Iterate over each estimators\n",
    "for n_estimators in param_grid_random_forest['n_estimators']:\n",
    "    fold_accuracy = []\n",
    "    fold_precision = []\n",
    "    fold_recall = []\n",
    "    fold_f1 = []\n",
    "    \n",
    "    #Perform k-fold cross-validation on each estimator\n",
    "    for train_index, test_index in kf.split(X_train_scaled):\n",
    "        X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n",
    "        \n",
    "        random_forest_classifier = RandomForestClassifier(n_estimators=n_estimators)\n",
    "        random_forest_classifier.fit(X_train_fold, y_train_fold)\n",
    "        y_pred_fold = random_forest_classifier.predict(X_val_fold)\n",
    "        \n",
    "        fold_accuracy.append(accuracy_score(y_val_fold, y_pred_fold))\n",
    "        fold_precision.append(precision_score(y_val_fold, y_pred_fold))\n",
    "        fold_recall.append(recall_score(y_val_fold, y_pred_fold))\n",
    "        fold_f1.append(f1_score(y_val_fold, y_pred_fold))\n",
    "    \n",
    "    #average scores across folds\n",
    "    accuracy_random_forest.append(np.mean(fold_accuracy))\n",
    "    precision_random_forest.append(np.mean(fold_precision))\n",
    "    recall_random_forest.append(np.mean(fold_recall))\n",
    "    f1_score_random_forest.append(np.mean(fold_f1))\n",
    "\n",
    "#find the best estimator depends on the average accuracy form each fold\n",
    "best_index = np.argmax(accuracy_random_forest)\n",
    "best_n_estimators = param_grid_random_forest['n_estimators'][best_index]\n",
    "\n",
    "#train the best model\n",
    "best_random_forest_classifier = RandomForestClassifier(n_estimators=best_n_estimators)\n",
    "best_random_forest_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Predictions\n",
    "y_pred_random_forest = best_random_forest_classifier.predict(X_test_scaled)\n",
    "\n",
    "#Evaluation\n",
    "accuracy_random_forest = accuracy_score(y_test, y_pred_random_forest)\n",
    "precision_random_forest = precision_score(y_test, y_pred_random_forest)\n",
    "recall_random_forest = recall_score(y_test, y_pred_random_forest)\n",
    "f1_score_random_forest = f1_score(y_test, y_pred_random_forest)\n",
    "confusion_matrix_random_forest = confusion_matrix(y_test, y_pred_random_forest)\n",
    "print(\"Best n_estimators:\", best_n_estimators)\n",
    "print(\"Random Forest Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_random_forest)\n",
    "print(\"Precision:\", precision_random_forest)\n",
    "print(\"Recall:\", recall_random_forest)\n",
    "print(\"F1-score:\", f1_score_random_forest)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_random_forest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from f1 classifier using Random forests , then adaboost (with tuning parameters) is the best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
